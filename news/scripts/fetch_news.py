#!/usr/bin/env python3
"""
News Aggregator - Enhanced Version
æ”¯æŒå¼‚æ­¥å¹¶å‘ã€æ™ºèƒ½ç¼“å­˜ã€å¥åº·ç›‘æ§ã€è®¢é˜…æ¨¡å¼ç­‰åŠŸèƒ½
"""
import argparse
import asyncio
import json
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent))

# é¦–å…ˆå¯¼å…¥å¹¶é…ç½®ç¼–ç å·¥å…·
from encoding_utils import setup_utf8_output, safe_print, safe_write
setup_utf8_output()

from config import get_config
from logger import get_logger
from cache import get_cache
from health import get_health_monitor
from keywords import get_expander
from ui import ProgressBar, OutputFormatter, InteractiveConfig
from subscription import get_subscription_manager, create_quick_subscription

# å¯¼å…¥å¼‚æ­¥è·å–å™¨ï¼ˆå¦‚æœ aiohttp å¯ç”¨ï¼‰
try:
    import aiohttp
    from async_fetcher import AsyncNewsFetcher
    ASYNC_AVAILABLE = True
except ImportError:
    ASYNC_AVAILABLE = False
    AsyncNewsFetcher = None


class NewsAggregatorCLI:
    """æ–°é—»èšåˆå™¨ CLI"""

    def __init__(self):
        self.config = get_config()
        self.logger = get_logger()
        self.cache = get_cache()
        self.health_monitor = get_health_monitor()
        self.keyword_expander = get_expander()
        self.formatter = OutputFormatter()

        # å¯ç”¨çš„æ•°æ®æº
        self.all_sources = [
            'hackernews', 'github', 'weibo', '36kr', 'v2ex',
            'tencent', 'wallstreetcn', 'producthunt', 'reddit', 'techcrunch'
        ]

    def parse_sources(self, source_str: str) -> List[str]:
        """è§£ææ•°æ®æºå‚æ•°"""
        if source_str == 'all':
            return [s for s in self.all_sources
                    if self.config.sources[s].enabled]
        return [s.strip() for s in source_str.split(',')
                if s.strip() in self.config.sources]

    def expand_keyword(self, keyword: Optional[str]) -> Optional[str]:
        """æ‰©å±•å…³é”®è¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        if not keyword or not self.config.smart_keyword_expansion:
            return keyword
        return self.keyword_expander.expand(keyword)

    async def fetch_async(
        self,
        sources: List[str],
        limit: int,
        keyword: Optional[str],
        deep: bool
    ) -> List[Dict[str, Any]]:
        """å¼‚æ­¥è·å–æ–°é—»"""
        async with AsyncNewsFetcher() as fetcher:
            # å¹¶å‘è·å–
            items = await fetcher.fetch_all_sources(sources, limit, keyword)

            # æ·±åº¦è·å–å†…å®¹
            if deep and items:
                items = await fetcher.enrich_with_content(items)

            return items

    def fetch_sync_fallback(
        self,
        sources: List[str],
        limit: int,
        keyword: Optional[str]
    ) -> List[Dict[str, Any]]:
        """åŒæ­¥å›é€€æ–¹æ³•ï¼ˆä½¿ç”¨æ—§çš„ requests å®ç°ï¼‰"""
        # è¿™é‡Œä¿ç•™åŸæœ‰çš„åŒæ­¥å®ç°ä½œä¸ºå›é€€
        # ä¸ºç®€æ´èµ·è§ï¼Œè¿™é‡Œä»…è¿”å›ç©ºåˆ—è¡¨
        self.logger.warning("ä½¿ç”¨åŒæ­¥å›é€€æ–¹æ³•ï¼ŒåŠŸèƒ½å—é™")
        return []

    def run(
        self,
        sources: List[str],
        limit: int = 10,
        keyword: Optional[str] = None,
        deep: bool = False,
        output_format: str = "json",
        use_cache: bool = True,
        expand_keywords: bool = True
    ) -> List[Dict[str, Any]]:
        """è¿è¡Œæ–°é—»èšåˆå™¨"""
        self.logger.info(f"å¼€å§‹è·å–æ–°é—»ï¼Œæ•°æ®æº: {sources}")

        # æ‰©å±•å…³é”®è¯
        if expand_keywords and keyword:
            keyword = self.expand_keyword(keyword)

        all_items = []

        # æ£€æŸ¥ç¼“å­˜
        if use_cache:
            for source in sources:
                cached = self.cache.get(source, keyword)
                if cached:
                    all_items.extend(cached)
                    self.logger.info(f"ä»ç¼“å­˜åŠ è½½: {source} ({len(cached)} æ¡)")

        # ç¡®å®šéœ€è¦è·å–çš„æº
        sources_to_fetch = [s for s in sources if s not in [i.get('source', '').lower().replace(' ', '_') for i in all_items]]

        if not sources_to_fetch:
            self.logger.info("æ‰€æœ‰æ•°æ®å‡æ¥è‡ªç¼“å­˜")
            return all_items[:limit]

        # ä½¿ç”¨å¼‚æ­¥æˆ–åŒæ­¥æ–¹æ³•
        if ASYNC_AVAILABLE and self.config.performance.async_enabled:
            try:
                items = asyncio.run(self.fetch_async(sources_to_fetch, limit, keyword, deep))
            except Exception as e:
                self.logger.error(f"å¼‚æ­¥è·å–å¤±è´¥: {e}")
                items = self.fetch_sync_fallback(sources_to_fetch, limit, keyword)
        else:
            items = self.fetch_sync_fallback(sources_to_fetch, limit, keyword)

        # æ›´æ–°ç¼“å­˜
        if use_cache and items:
            for source in sources_to_fetch:
                source_items = [i for i in items if i.get('source', '').lower().replace(' ', '_') == source]
                if source_items:
                    self.cache.set(source, source_items, keyword)

        all_items.extend(items)
        self.logger.info(f"å…±è·å– {len(all_items)} æ¡æ–°é—»")

        return all_items

    def output(self, items: List[Dict[str, Any]], format: str = "json", save: bool = True):
        """è¾“å‡ºç»“æœ"""
        if format == "json":
            content = self.formatter.format_json(items)
            safe_write(content)
        elif format == "markdown":
            content = self.formatter.format_markdown(items)
            safe_write(content)
        elif format == "html":
            content = self.formatter.format_html(items)
            safe_write(content)

        # ä¿å­˜æŠ¥å‘Š
        if save and items:
            report_path = self.formatter.save_report(content, format)
            if report_path:
                safe_print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")


def main():
    """ä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        description="News Aggregator - å…¨ç½‘çƒ­ç‚¹æ–°é—»èšåˆå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è·å– Hacker News å‰ 15 æ¡
  python fetch_news.py --source hackernews --limit 15

  # è·å– AI ç›¸å…³æ–°é—»ï¼ˆå¸¦æ™ºèƒ½å…³é”®è¯æ‰©å±•ï¼‰
  python fetch_news.py --source all --keyword "AI" --limit 20

  # æ·±åº¦è·å–æ–‡ç« å†…å®¹
  python fetch_news.py --source hackernews,github --limit 10 --deep

  # è¾“å‡º Markdown æ ¼å¼
  python fetch_news.py --source all --format markdown

  # äº¤äº’å¼é…ç½®
  python fetch_news.py --interactive

  # æŸ¥çœ‹å¥åº·çŠ¶æ€
  python fetch_news.py --health

  # ç®¡ç†è®¢é˜…
  python fetch_news.py --subscription status
  python fetch_news.py --subscription run
        """
    )

    parser.add_argument('--source', '-s', default='all',
                       help='æ•°æ®æºï¼ˆé€—å·åˆ†éš”æˆ– allï¼‰')
    parser.add_argument('--limit', '-l', type=int, default=10,
                       help='æ¯ä¸ªæ•°æ®æºçš„æ¡æ•°é™åˆ¶')
    parser.add_argument('--keyword', '-k', help='å…³é”®è¯è¿‡æ»¤ï¼ˆé€—å·åˆ†éš”ï¼‰')
    parser.add_argument('--deep', '-d', action='store_true',
                       help='æ·±åº¦è·å–æ–‡ç« å†…å®¹')
    parser.add_argument('--format', '-f', choices=['json', 'markdown', 'html'],
                       default='json', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--no-cache', action='store_true',
                       help='ç¦ç”¨ç¼“å­˜')
    parser.add_argument('--no-expand', action='store_true',
                       help='ç¦ç”¨å…³é”®è¯æ™ºèƒ½æ‰©å±•')
    parser.add_argument('--interactive', '-i', action='store_true',
                       help='äº¤äº’å¼é…ç½®')
    parser.add_argument('--health', action='store_true',
                       help='æ˜¾ç¤ºå¥åº·çŠ¶æ€æŠ¥å‘Š')
    parser.add_argument('--subscription', nargs='?', const='status',
                       choices=['status', 'run', 'list'],
                       help='è®¢é˜…ç®¡ç†')
    parser.add_argument('--save', action='store_true', default=True,
                       help='ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='è¯¦ç»†æ—¥å¿—è¾“å‡º')

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        get_logger().logger.setLevel(logging.DEBUG)

    cli = NewsAggregatorCLI()

    # å¤„ç†ç‰¹æ®Šå‘½ä»¤
    if args.health:
        report = cli.health_monitor.get_health_report()
        safe_write(report)
        return

    if args.subscription:
        sub_manager = get_subscription_manager()

        if args.subscription == 'status':
            print(sub_manager.get_status())
        elif args.subscription == 'list':
            for sub in sub_manager.list_all():
                print(f"  - {sub.name}: {', '.join(sub.sources)}")
        elif args.subscription == 'run':
            due = sub_manager.get_due_subscriptions()
            if not due:
                print("æ²¡æœ‰éœ€è¦è¿è¡Œçš„è®¢é˜…")
                return

            print(f"è¿è¡Œ {len(due)} ä¸ªè®¢é˜…...")
            for sub in due:
                print(f"\næ‰§è¡Œè®¢é˜…: {sub.name}")
                items = cli.run(
                    cli.parse_sources(','.join(sub.sources)),
                    limit=args.limit,
                    keyword=sub.keywords,
                    deep=sub.deep_fetch,
                    use_cache=not args.no_cache
                )
                cli.output(items, sub.output_format, save=args.save)
                sub_manager.update_last_run(sub.name)
        return

    # äº¤äº’å¼æ¨¡å¼
    if args.interactive:
        config = InteractiveConfig()
        sources = config.prompt_sources()
        keyword = config.prompt_keyword()
        output_format = config.prompt_format()

        items = cli.run(
            sources,
            limit=args.limit,
            keyword=keyword,
            deep=args.deep,
            use_cache=not args.no_cache
        )
        cli.output(items, output_format, save=args.save)
        return

    # æ­£å¸¸æ¨¡å¼
    sources = cli.parse_sources(args.source)
    if not sources:
        print("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„æ•°æ®æº", file=sys.stderr)
        sys.exit(1)

    items = cli.run(
        sources,
        limit=args.limit,
        keyword=args.keyword,
        deep=args.deep,
        output_format=args.format,
        use_cache=not args.no_cache,
        expand_keywords=not args.no_expand
    )

    cli.output(items, args.format, save=args.save)


if __name__ == "__main__":
    main()
