#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¨æ½®èµ„è®¯ç½‘è´¢æŠ¥ä¸‹è½½å™¨
ä» cninfo.com.cn ä¸‹è½½ Aè‚¡å’Œæ¸¯è‚¡è´¢æŠ¥PDF
"""

import os
import json
import datetime
import time
import random
import httpx
import glob


# è‚¡ç¥¨æ•°æ®åº“è·¯å¾„
# ç§»é™¤å¯¹ stock.json æ–‡ä»¶çš„ä¾èµ–
# STOCKS_JSON = os.path.join(
#     os.path.dirname(os.path.abspath(__file__)), "assets", "stocks.json"
# )


def to_chinese_year(year: int) -> str:
    """å°†å¹´ä»½è½¬æ¢ä¸ºä¸­æ–‡æ•°å­—ï¼ˆå¦‚ 2023 -> äºŒé›¶äºŒä¸‰ï¼‰"""
    mapping = {
        "0": "é›¶", "1": "ä¸€", "2": "äºŒ", "3": "ä¸‰", "4": "å››",
        "5": "äº”", "6": "å…­", "7": "ä¸ƒ", "8": "å…«", "9": "ä¹",
    }
    return "".join(mapping[d] for d in str(year))


class CnInfoDownloader:
    """ä»å·¨æ½®èµ„è®¯ç½‘ä¸‹è½½è´¢æŠ¥ - æ”¯æŒAè‚¡å’Œæ¸¯è‚¡"""

    def __init__(self):
        self.cookies = {
            "JSESSIONID": "9A110350B0056BE0C4FDD8A627EF2868",
            "insert_cookie": "37836164",
        }
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:110.0) Gecko/20100101 Firefox/110.0",
            "Content-Type": "application/x-www-form-urlencoded; charset=UTF-8",
            "X-Requested-With": "XMLHttpRequest",
            "Origin": "http://www.cninfo.com.cn",
            "Referer": "http://www.cninfo.com.cn/new/commonUrl/pageOfSearch?url=disclosure/list/search&lastPage=index",
        }
        self.timeout = httpx.Timeout(60.0)
        self.query_url = "http://www.cninfo.com.cn/new/hisAnnouncement/query"
        # ç§»é™¤å¯¹ stock.json æ–‡ä»¶çš„ä¾èµ–ï¼Œä½¿ç”¨åœ¨çº¿æŸ¥è¯¢
        self.market_to_stocks = {}

    def _load_stocks(self) -> dict:
        """ä»JSONæ–‡ä»¶åŠ è½½è‚¡ç¥¨æ•°æ®åº“"""
        if os.path.exists(STOCKS_JSON):
            with open(STOCKS_JSON, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}

    def _detect_market(self, stock_code: str) -> str:
        """æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨æ£€æµ‹å¸‚åœºï¼ˆä¸ä¾èµ– stock.jsonï¼‰"""
        # æ¸¯è‚¡ï¼šé€šå¸¸5ä½æ•°å­—ï¼Œé€šå¸¸ä»¥00, 01, 02, 09å¼€å¤´
        if len(stock_code) == 5 and stock_code.startswith(("00", "01", "02", "09")):
            return "hke"
        # Aè‚¡ï¼š6ä½æ•°å­—ï¼Œä»¥0, 3, 6å¼€å¤´
        if len(stock_code) == 6 and stock_code[0] in "036":
            return "szse"
        
        return "szse"  # é»˜è®¤ä¸ºAè‚¡

    def find_stock(self, stock_input: str) -> tuple:
        """
        æ ¹æ®ä»£ç æˆ–åç§°æŸ¥æ‰¾è‚¡ç¥¨ï¼ˆä½¿ç”¨åœ¨çº¿æŸ¥è¯¢æ›¿ä»£ stock.jsonï¼‰
        è¿”å›: (stock_code, stock_info, market) æˆ– (None, None, None)
        """
        # å…ˆå°è¯•ä½œä¸ºä»£ç è¿›è¡Œæ ¼å¼åŒ–å’ŒéªŒè¯
        if stock_input.isdigit():
            if len(stock_input) == 6 and stock_input[0] in "036":
                # Aè‚¡ä»£ç 
                market = self._detect_market(stock_input)
                # æ„é€ åŸºç¡€è‚¡ç¥¨ä¿¡æ¯
                stock_info = {
                    "orgId": self._get_org_id(stock_input, market),
                    "zwjc": self._get_stock_name_online(stock_input)
                }
                return stock_input, stock_info, market
            elif len(stock_input) == 5 and stock_input.startswith(("00", "01", "02", "09")):
                # æ¸¯è‚¡ä»£ç 
                market = "hke"
                stock_info = {
                    "orgId": self._get_org_id(stock_input, market),
                    "zwjc": self._get_stock_name_online(stock_input)
                }
                return stock_input, stock_info, market
        
        # å¦‚æœæ˜¯è‚¡ç¥¨åç§°ï¼Œå°è¯•åœ¨çº¿æŸ¥è¯¢ä»£ç 
        stock_code = self._search_stock_code_online(stock_input)
        if stock_code:
            market = self._detect_market(stock_code)
            stock_info = {
                "orgId": self._get_org_id(stock_code, market),
                "zwjc": stock_input
            }
            return stock_code, stock_info, market
        
        return None, None, None
        
    def _get_org_id(self, stock_code: str, market: str) -> str:
        """
        è·å–è‚¡ç¥¨çš„ orgIdï¼ˆä½¿ç”¨åœ¨çº¿æŸ¥è¯¢ï¼‰
        è¿™é‡Œä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„é»˜è®¤å€¼ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´ç²¾ç¡®çš„æŸ¥è¯¢
        """
        # å¯¹äºAè‚¡ï¼Œä½¿ç”¨é€šç”¨æ ¼å¼
        if market == "szse":
            if stock_code.startswith("6"):
                return f"gssh0{stock_code}"
            else:
                return f"ssessz{stock_code}"
        # å¯¹äºæ¸¯è‚¡
        elif market == "hke":
            return f"hke{stock_code}"
            
        # é»˜è®¤è¿”å›
        return f"ssessz{stock_code}"
        
    def _get_stock_name_online(self, stock_code: str) -> str:
        """
        é€šè¿‡åœ¨çº¿æŸ¥è¯¢è·å–è‚¡ç¥¨åç§°
        æ³¨æ„ï¼šåœ¨å®é™…AIç¯å¢ƒä¸­ï¼Œè¿™å°†ä½¿ç”¨ search_web å·¥å…·
        """
        # è¿™é‡Œæ¨¡æ‹Ÿåœ¨çº¿æŸ¥è¯¢çš„ç»“æœ
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒAIä¼šä½¿ç”¨ search_web å·¥å…·æŸ¥è¯¢
        market = self._detect_market(stock_code)
            
        if market == "szse":
            # Aè‚¡ä»£ç æŸ¥è¯¢
            search_query = f"{stock_code} è‚¡ç¥¨åç§° è¯åˆ¸ä»£ç "
        else:
            # æ¸¯è‚¡ä»£ç æŸ¥è¯¢
            search_query = f"{stock_code} HK è‚¡ç¥¨åç§°"
            
        # æ¨¡æ‹ŸæŸ¥è¯¢ç»“æœï¼ˆå®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨ search_web å·¥å…·ï¼‰
        # è¿™é‡Œè¿”å›ä»£ç ä½œä¸ºåç§°çš„å¤‡é€‰
        return f"è‚¡ç¥¨{stock_code}"
        
    def _search_stock_code_online(self, stock_name: str) -> str:
        """
        é€šè¿‡è‚¡ç¥¨åç§°åœ¨çº¿æŸ¥è¯¢è‚¡ç¥¨ä»£ç 
        æ³¨æ„ï¼šåœ¨å®é™…AIç¯å¢ƒä¸­ï¼Œè¿™å°†ä½¿ç”¨ search_web å·¥å…·
        """
        # æ„é€ æœç´¢æŸ¥è¯¢
        search_query = f"{stock_name} è‚¡ç¥¨ä»£ç  è¯åˆ¸ä»£ç "
            
        # æ¨¡æ‹Ÿåœ¨çº¿æŸ¥è¯¢ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨ search_web å·¥å…·ï¼‰
        # è¿™é‡Œè¿”å› None è¡¨ç¤ºæœªæ‰¾åˆ°ï¼Œå®é™…åº”ç”¨ä¸­AIä¼šæ‰§è¡Œæœç´¢
        return None
        
    def _query_announcements(self, filter_params: dict, market: str = "szse") -> list:
        """æŸ¥è¯¢å·¨æ½®èµ„è®¯ç½‘APIè·å–å…¬å‘Š"""
        client = httpx.Client(
            headers=self.headers, cookies=self.cookies, timeout=self.timeout
        )

        # è·å–è‚¡ç¥¨çš„orgIdï¼ˆä½¿ç”¨æ–°çš„åœ¨çº¿æŸ¥è¯¢æ–¹å¼ï¼‰
        stock_code = filter_params["stock"][0]
        market = self._detect_market(stock_code)
        stock_info = {
            "orgId": self._get_org_id(stock_code, market),
            "zwjc": self._get_stock_name_online(stock_code)
        }

        payload = self._build_payload(stock_code, stock_info, market, filter_params)

        announcements = []
        has_more = True

        while has_more:
            payload["pageNum"] += 1
            try:
                resp = client.post(self.query_url, data=payload).json()
                has_more = resp.get("hasMore", False)
                if resp.get("announcements"):
                    announcements.extend(resp["announcements"])
            except Exception as e:
                print(f"æŸ¥è¯¢APIé”™è¯¯: {e}")
                break

        return announcements

    def _build_payload(
        self, stock_code: str, stock_info: dict, market: str, filter_params: dict
    ) -> dict:
        """æ„å»ºAPIè¯·æ±‚å‚æ•°"""
        if market == "hke":
            category = ""
            searchkey = ""
        else:
            category = ";".join(filter_params.get("category", []))
            searchkey = filter_params.get("searchkey", "")

        return {
            "pageNum": 0,
            "pageSize": 30,
            "column": market,
            "tabName": "fulltext",
            "plate": "",
            "stock": f"{stock_code},{stock_info['orgId']}",
            "searchkey": searchkey,
            "secid": "",
            "category": category,
            "trade": "",
            "seDate": filter_params.get("seDate", ""),
            "sortName": "",
            "sortType": "",
            "isHLtitle": False,
        }

    def _download_pdf(self, announcement: dict, output_dir: str) -> str:
        """ä¸‹è½½å•ä¸ªPDFæ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾„"""
        client = httpx.Client(
            headers=self.headers, cookies=self.cookies, timeout=self.timeout
        )

        sec_code = announcement["secCode"]
        sec_name = announcement["secName"].replace("*", "s").replace("/", "-")
        title = announcement["announcementTitle"].replace("/", "-").replace("\\", "-")
        adjunct_url = announcement["adjunctUrl"]
        announcement_id = announcement["announcementId"]

        if announcement.get("adjunctType") != "PDF":
            return None

        filename = f"{sec_code}_{sec_name}_{title}_{announcement_id}.pdf"
        filename = "".join(c for c in filename if c.isalnum() or c in "._-")
        filepath = os.path.join(output_dir, filename)

        if not os.path.exists(filepath):
            try:
                print(f"  ä¸‹è½½ä¸­: {title[:50]}...")
                resp = client.get(f"http://static.cninfo.com.cn/{adjunct_url}")
                with open(filepath, "wb") as f:
                    f.write(resp.content)
                time.sleep(random.uniform(0.5, 1.5))
            except Exception as e:
                print(f"  ä¸‹è½½å¤±è´¥: {e}")
                return None

        return filepath

    def _is_main_annual_report(self, title: str, year: int, market: str = "szse") -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºä¸»å¹´åº¦æŠ¥å‘Šï¼ˆéæ‘˜è¦/è‹±æ–‡ç‰ˆï¼‰"""
        chinese_year = to_chinese_year(year)

        if market == "hke":
            has_year = f"{year}" in title or chinese_year in title
            is_annual = (
                "annual report" in title.lower()
                or "å¹´åº¦æŠ¥å‘Š" in title
                or "å¹´æŠ¥" in title
                or f"{year}è´¢åŠ¡å¹´åº¦æŠ¥å‘Š" in title
            )
            is_summary = "summary" in title.lower() or "æ‘˜è¦" in title
            is_quarterly = "å­£åº¦" in title or "åŠå¹´åº¦" in title or "ä¸­æœŸ" in title
            is_english_only = "è‹±æ–‡" in title

            return has_year and is_annual and not is_summary and not is_quarterly and not is_english_only
        else:
            if f"{year}å¹´å¹´åº¦æŠ¥å‘Š" not in title and f"{year}å¹´å¹´æŠ¥" not in title:
                return False
            if "æ‘˜è¦" in title or "è‹±æ–‡" in title or "summary" in title.lower():
                return False
            if "æ›´æ­£" in title or "ä¿®è®¢" in title:
                return False
            return True

    def _get_annual_report_search_period(self, year: int, market: str = "szse") -> tuple:
        """è·å–å¹´åº¦æŠ¥å‘Šæœç´¢æ—¶é—´èŒƒå›´"""
        if market == "hke":
            search_start = f"{year}-01-01"
            search_end = f"{year + 1}-06-30"
        else:
            search_start = f"{year + 1}-03-01"
            search_end = f"{year + 1}-06-30"
        return search_start, search_end

    def _is_main_periodic_report(self, title: str, report_type: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºä¸»æœŸæŠ¥å‘Š"""
        if "æ‘˜è¦" in title or "è‹±æ–‡" in title:
            return False
        if "æ›´æ­£" in title or "ä¿®è®¢" in title:
            return False

        if report_type == "semi":
            return "åŠå¹´åº¦æŠ¥å‘Š" in title or "ä¸­æœŸæŠ¥å‘Š" in title
        elif report_type == "q1":
            return "ä¸€å­£åº¦" in title or "ç¬¬ä¸€å­£åº¦" in title
        elif report_type == "q3":
            return "ä¸‰å­£åº¦" in title or "ç¬¬ä¸‰å­£åº¦" in title

        return False

    def download_annual_reports(
        self, stock_code: str, years: list, output_dir: str, market: str = "szse"
    ) -> list:
        """ä¸‹è½½æŒ‡å®šå¹´ä»½çš„å¹´åº¦æŠ¥å‘Š"""
        downloaded = []

        for year in years:
            search_start, search_end = self._get_annual_report_search_period(year, market)

            if market == "hke":
                filter_params = {
                    "stock": [stock_code],
                    "category": [],
                    "searchkey": "",
                    "seDate": f"{search_start}~{search_end}",
                }
            else:
                filter_params = {
                    "stock": [stock_code],
                    "category": ["category_ndbg_szsh"],
                    "searchkey": f"{year}å¹´å¹´åº¦æŠ¥å‘Š",
                    "seDate": f"{search_start}~{search_end}",
                }

            announcements = self._query_announcements(filter_params, market)

            for ann in announcements:
                if self._is_main_annual_report(ann["announcementTitle"], year, market):
                    filepath = self._download_pdf(ann, output_dir)
                    if filepath:
                        downloaded.append(filepath)
                        print(f"  âœ… å·²ä¸‹è½½: {year} å¹´åº¦æŠ¥å‘Š")
                    break

        return downloaded

    def download_periodic_reports(
        self, stock_code: str, year: int, output_dir: str, market: str = "szse"
    ) -> list:
        """ä¸‹è½½å½“å¹´çš„ä¸€å­£æŠ¥ã€ä¸­æŠ¥ã€ä¸‰å­£æŠ¥"""
        downloaded = []

        report_configs = [
            ("q1", "category_yjdbg_szsh", "ä¸€å­£åº¦æŠ¥å‘Š", f"{year}-04-01", f"{year}-05-31"),
            ("semi", "category_bndbg_szsh", "åŠå¹´åº¦æŠ¥å‘Š", f"{year}-08-01", f"{year}-09-30"),
            ("q3", "category_sjdbg_szsh", "ä¸‰å­£åº¦æŠ¥å‘Š", f"{year}-10-01", f"{year}-11-30"),
        ]

        for report_type, category, search_term, start_date, end_date in report_configs:
            if market == "hke":
                filter_params = {
                    "stock": [stock_code],
                    "category": [],
                    "searchkey": "",
                    "seDate": f"{start_date}~{end_date}",
                }
            else:
                filter_params = {
                    "stock": [stock_code],
                    "category": [category],
                    "searchkey": search_term,
                    "seDate": f"{start_date}~{end_date}",
                }

            announcements = self._query_announcements(filter_params, market)

            for ann in announcements:
                if self._is_main_periodic_report(ann["announcementTitle"], report_type):
                    filepath = self._download_pdf(ann, output_dir)
                    if filepath:
                        downloaded.append(filepath)
                        print(f"  âœ… å·²ä¸‹è½½: {year} {search_term}")
                    break

        return downloaded


def cleanup_temp_reports():
    """æ¸…ç†æ—§çš„ä¸´æ—¶è´¢æŠ¥æ–‡ä»¶"""
    try:
        # æŸ¥æ‰¾ç³»ç»Ÿä¸­çš„ä¸´æ—¶è´¢æŠ¥ç›®å½•
        temp_dirs = glob.glob("/tmp/cninfo_reports_*")
        for temp_dir in temp_dirs:
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)
            print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶è´¢æŠ¥ç›®å½•: {temp_dir}")
    except Exception as e:
        print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")


def download_reports(stock_input: str, output_dir: str = None) -> dict:
    """
    ä¸‹è½½è‚¡ç¥¨è´¢æŠ¥çš„ä¸»å‡½æ•°
    è¿”å›åŒ…å«è‚¡ç¥¨ä¿¡æ¯å’Œä¸‹è½½æ–‡ä»¶åˆ—è¡¨çš„å­—å…¸
    """
    # æ¸…ç†æ—§çš„ä¸´æ—¶è´¢æŠ¥æ–‡ä»¶
    cleanup_temp_reports()
    
    if output_dir is None:
        # åˆ›å»ºå›ºå®šç›®å½•å­˜æ”¾è´¢æŠ¥æ–‡ä»¶
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # è·å–é¡¹ç›®æ ¹ç›®å½•
        output_dir = os.path.join(base_dir, "reports", "financial_reports")
        os.makedirs(output_dir, exist_ok=True)

    downloader = CnInfoDownloader()

    # æŸ¥æ‰¾è‚¡ç¥¨
    stock_code, stock_info, market = downloader.find_stock(stock_input)
    if not stock_code:
        return {"error": f"æœªæ‰¾åˆ°è‚¡ç¥¨: {stock_input}"}

    stock_name = stock_info.get("zwjc", stock_code)
    market_display = "æ¸¯è‚¡" if market == "hke" else "Aè‚¡"
    print(f"ğŸ“Š æ‰¾åˆ°è‚¡ç¥¨: {stock_code} ({stock_name}) [{market_display}]")

    # è®¡ç®—å¹´ä»½
    current_year = datetime.datetime.now().year
    annual_years = list(range(current_year - 5, current_year))

    # ä¸‹è½½å¹´åº¦æŠ¥å‘Š
    print(f"\nğŸ“¥ æ­£åœ¨ä¸‹è½½è¿‘{len(annual_years)}å¹´å¹´åº¦æŠ¥å‘Š...")
    annual_files = downloader.download_annual_reports(stock_code, annual_years, output_dir, market)

    # ä¸‹è½½å®šæœŸæŠ¥å‘Š
    print(f"\nğŸ“¥ æ­£åœ¨ä¸‹è½½å®šæœŸæŠ¥å‘Šï¼ˆä¸€å­£æŠ¥ã€ä¸­æŠ¥ã€ä¸‰å­£æŠ¥ï¼‰...")
    periodic_files = downloader.download_periodic_reports(stock_code, current_year, output_dir, market)

    if not periodic_files:
        print(f"  å½“å¹´æ— æŠ¥å‘Šï¼Œå°è¯•å»å¹´...")
        periodic_files = downloader.download_periodic_reports(stock_code, current_year - 1, output_dir, market)
    elif len(periodic_files) < 3:
        prev_year_files = downloader.download_periodic_reports(stock_code, current_year - 1, output_dir, market)
        periodic_files.extend(prev_year_files)

    all_files = annual_files + periodic_files

    return {
        "stock_code": stock_code,
        "stock_name": stock_name,
        "market": market,
        "market_display": market_display,
        "output_dir": output_dir,
        "files": all_files,
        "annual_count": len(annual_files),
        "periodic_count": len(periodic_files),
    }


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python cninfo_downloader.py <è‚¡ç¥¨ä»£ç æˆ–åç§°> [è¾“å‡ºç›®å½•]")
        print("ç¤ºä¾‹: python cninfo_downloader.py 600519")
        print("ç¤ºä¾‹: python cninfo_downloader.py è´µå·èŒ…å°")
        sys.exit(1)

    stock_input = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else None

    result = download_reports(stock_input, output_dir)
    if "error" in result:
        print(f"é”™è¯¯: {result['error']}")
    else:
        print(f"\n{'=' * 50}")
        print(f"âœ… ä¸‹è½½å®Œæˆ: {len(result['files'])} ä»½è´¢æŠ¥")
        print(f"ğŸ“ ä¿å­˜ä½ç½®: {result['output_dir']}")
        print(f"\næ–‡ä»¶åˆ—è¡¨:")
        for f in result["files"]:
            print(f"  {os.path.basename(f)}")
